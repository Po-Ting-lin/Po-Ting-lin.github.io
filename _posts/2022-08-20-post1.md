---
layout: post
title: "Integral Image in CUDA"
date: 2022-08-20
description: "Implement and modified an integral image in CUDA"
img_url: assets/img/post1/integral_image.png
tags: [Image Processing, CUDA]
---

## Introduction
Implementation of integral image, according to the paper[1].  
The paper proposed "Blocked Integral Image" which can expose more parallelism than the version of cv::cuda::integral.

## References
```
[1] Dang, Qingqing, Shengen Yan, and Ren Wu. 
    "A fast integral image generation algorithm on GPUs." 
    2014 20th IEEE International Conference on Parallel and Distributed Systems (ICPADS). IEEE, 2014.
```

## Integral Image

If we want to query the summation of some area in the image. It is recommended to build an integral image first.  
An integral image can be regarded as a look-up table, a single query time complexity reduces from O(wh) to O(1).

<img src="/assets/img/post1/integral_image.png">  

Integral image can be used in several image processing algorithm,  
including template matching, covariance matrix calculation, average filter, and so on.

## Parallel Scan

Scan or called prefix sum is a basic operation to build integral image.  
In the other way to think, scan is one-dimensional integral image.
We can accumulate the sum by 1 thread, but it costs O(n).  

A tree-based parallel scan is used in the paper[1], which has the linear time complexity.

<img src="/assets/img/post1/up_sweep.png">  
Up-sweep  
  
<img src="/assets/img/post1/down_sweep.png">  
Down-sweep

However, the non-coalescing global memory access cause a great penalty on GPU application.  
The ideal implementation on GPU is using shared memory to reuse the data on it.

## Shfl Scan

CUDA intrinsic function provides warp shuffle, it is a faster mechanism and fit the GPU SIMT fashion.   
We must take the advantage of warp-level primitives in our gpu application.

```C
T __shfl_up_sync(unsigned mask, T var, unsigned int delta);
```

<img src="/assets/img/post1/shfl_scan.png">  
Local shfl scan. It takes log2(n) passes, and O(n) operations per pass.  

Rather than using parallel scan, I use shfl scan in my implementation.

## Scan-Transpose-Scan



## Blocked Scan


## Performance

Method               |Image Size     | Elapsed Time
---------------------|:-------------:|--------------
OpenCV CUDA module   |256 * 256      |  0.53 ms
Modified block method|256 * 256      |  0.14 ms (x3.78 speedup)
OpenCV CUDA module   |1024 * 1024    |  1.86 ms
Modified block method|1024 * 1024    |  0.82 ms (x2.26 speedup)
OpenCV CUDA module   |5120 * 5120    |  26.37 ms
Modified block method|5120 * 5120    |  17.71 ms (x1.48 speedup)


## Conclusion
