---
layout: post
title: "Integral Image in CUDA"
date: 2022-08-20
description: "Implement and modified an integral image in CUDA"
img_url: assets/img/post1/integral_image.png
tags: [application,CUDA]
---

## Introduction
Implementation of integral image, according to the paper[1].  
The paper proposed "Blocked Integral Image" which can expose more parallelism than the version of cv::cuda::integral.

## References
```
[1] Dang, Qingqing, Shengen Yan, and Ren Wu. 
    "A fast integral image generation algorithm on GPUs." 
    2014 20th IEEE International Conference on Parallel and Distributed Systems (ICPADS). IEEE, 2014.
```

## Introduction of Integral Image

If we want to query the summation of some area in the image. It is recommended to build an integral image first.  
An integral image can be regarded as a look-up table, a single query time complexity reduces from O(wh) to O(1).

<img src="/assets/img/post1/integral_image.png">  

Integral image can be used in several image processing algorithm,  
including template matching, covariance matrix calculation, average filter, and so on.

## Scan
### Parallel Scan

Scan or called prefix sum is a basic operation to build integral image.  
In the other way to think, scan is one-dimensional integral image.
We can accumulate the sum by 1 thread, but it costs O(n).  

A tree-based parallel scan is used in the paper[1], which has the linear time complexity.

<img src="/assets/img/post1/up_sweep.png">  
Up-sweep  
  
<img src="/assets/img/post1/down_sweep.png">  
Down-sweep

However, the non-coalescing global memory access cause a great penalty on GPU application.  
The ideal implementation on GPU is using shared memory to reuse the data on it.

### Shfl Scan

CUDA intrinsic function provides warp shuffle, it is a faster mechanism and fit the GPU SIMT fashion.   
We must take the advantage of warp-level primitives in our gpu application.

```C
T __shfl_up_sync(unsigned mask, T var, unsigned int delta);
```

<img src="/assets/img/post1/shfl_scan.png">  
Local shfl scan. It takes log2(n) passes, and O(n) operations per pass.  

Rather than using parallel scan, I use shfl scan in my implementation.

## CUDA Integral Image
### Scan-Transpose-Scan

This method including three phases, namely scan, transpose and scan, cause that global memory
needs to be accessed 6 * w * h times.   
Transpose has been well studied, and it has an efficient implementation.  
But it is still a IO-consuming application, so it is the bottleneck in Scan-Transpose-Scan.

### Blocked Scan

The author proposed Blocked Integral method.
<img src="/assets/img/post1/blocked.png">  

The main idea of this method is trying to do 2D Scan intra the block concurrently.
Here comes an issue.  
If we want to apply scan in a random block, we must get the pre-sum of the top and the left thread-block.
Then, we can scan based on the pre-sum value.

Stage 1 and stage 2 in this method build the pre-sum table (or called reduced matrix) first.  
Stage 3 look up the pre-sum table to scan in each thread-block concurrently. 

The method realizes that scanning in both inter-block and intra-block, so it exposes more parallelism.
It also avoids using transpose, and it is capable to makes a good use of shared memory.

## Performance

I implemented blocked Scan with some modifications, and compared with the existing opencv-cuda method.
The result shows "Modified Blocked method" outperform in every size of the input image.

Method                         |Image Size         | Elapsed Time
-------------------------------|:-----------------:|--------------
OpenCV CUDA module             |256 * 256          |  0.53 ms
Modified Blocked method        |256 * 256          |  0.14 ms (x3.78 speedup)
OpenCV CUDA module             |1024 * 1024        |  1.86 ms
Modified Blocked method        |1024 * 1024        |  0.82 ms (x2.26 speedup)
OpenCV CUDA module             |5120 * 5120        |  26.37 ms
Modified Blocked method        |5120 * 5120        |  17.71 ms (x1.48 speedup)

